
import numpy as np
print("Imported Successfully....")

import numpy as np 
arr = np.array([[1,2,3],[3,2,1], [5,4,2]])
print('Array                : \n', arr)
print('Array  datatype :',arr.dtype)
print('Array   shape   :',arr.shape)
print('Array   size    :',arr.size)


import numpy as np 
arr = np.array([1,2,3,4,5,6,7,8,9,10,11,12])
nearr = arr.reshape(4, 3) 
print(nearr)

import numpy as np 
arr = np.array([3,2,0,1])
print(np.sort(arr))
arr = np.array(['banana','cherry','apple'])
print(np.sort(arr))

import matplotlib as plt
print("Imported library successfully....")
print("Version = ",plt.__version__)

from matplotlib import pyplot as plt
x=[1,1,3,3,5,5]
y=[0,4,1,1,5,0]
plt.plot(x,y,'r-o')
plt.xlabel('X-axis')
plt.ylabel('Y-axis')
plt.title('Line graph')
plt.show()

from matplotlib import pyplot as plt
plt.bar([1,3,5],[5,4,2],label='One')
plt.bar([0,2,4],[3,4,5],label='Two')
plt.legend()
plt.show()

from matplotlib import pyplot as plt
plt.bar([1,3,5,],[5,4,3],label='One')
plt.bar([0,2,4],[3,4,5],label='Two')
plt.legend()
plt.xlabel('Number')
plt.ylabel('Height')
plt.title('bar Graph')
plt.show()

from matplotlib import pyplot as plt
x=[2,2,2,3,4,5,6,6,6]
y=[1,2,3,2,1,2,3,2,1]
plt.scatter(x,y,label='scatskit')
plt.xlabel('x-axis')
plt.ylabel('y-axis')
plt.title('Scatter plot')
plt.legend()
plt.show()

import matplotlib.pyplot as plt
import numpy as np
x = np.random.normal(170, 10, 250)
plt.hist(x)
plt.grid()
plt.xlabel('X-axis')
plt.ylabel('Y-axis')
plt.title('Histogram graph')
plt.show()

import pandas as pd
data=pd.read_csv(r"C:\Users\PRAJWAL\Downloads\iris_data.csv")
data.head()

          KNN

print(data.shape)
print(data.info())

x= data.iloc[:,:-1].values
y= data.iloc[:,-1].values

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2)

from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborsClassifier(n_neighbors=5,metric="euclidean")

knn.fit(x_train, y_train)
predictions=knn.predict(x_test)

from sklearn.metrics import confusion_matrix,accuracy_score
print(confusion_matrix(y_test, predictions))

print(accuracy_score(y_test, predictions))

        Logistic Regression

import pandas as pd
data=pd.read_csv(r"C:\Users\PRAJWAL\Downloads\iris_data.csv")
data.head()

print(data.shape)
data.info()

x= data.iloc[:,:-1].values
y= data.iloc[:,-1].values

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2)

from sklearn.linear_model import LogisticRegression
classifier= LogisticRegression(random_state=0)
classifier.fit(x_train, y_train)
predictions=classifier.predict(x_test) 

               :Naive Bayes:

import pandas as pd
data = pd.read_csv(r"C:\Users\PRAJWAL\Downloads\iris_data.csv")
data.head()

print(data.shape)
data.info()

x=data.iloc[:,:-1].values
y=data.iloc[:,-1].values

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2)

from sklearn.naive_bayes import GaussianNB
classifier = GaussianNB()
classifier.fit(x_train, y_train)
predictions=classifier.predict(x_test)

from sklearn.metrics import confusion_matrix,accuracy_score
print(confusion_matrix(y_test, predictions))

print(accuracy_score(y_test, predictions))

                    DT

import pandas as pd
data=pd.read_csv(r"C:\Users\PRAJWAL\Downloads\iris_data.csv")
data.head()

print(data.shape)
data.info()

x=data.iloc[:,:-1].values
y=data.iloc[:,-1].values

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2)

from sklearn.tree import DecisionTreeClassifier
classifier=DecisionTreeClassifier(criterion='entropy', random_state=0)
classifier.fit(x_train, y_train)

predictions=classifier.predict(x_test)

from sklearn.metrics import confusion_matrix,accuracy_score
print(confusion_matrix(y_test, predictions))

print(accuracy_score(y_test, predictions))

            SVM

import pandas as pd
data=pd.read_csv(r"C:\Users\PRAJWAL\Downloads\iris_data.csv")
data.head()

print(data.shape)
data.info()

x=data.iloc[:,:-1].values
y=data.iloc[:,-1].values

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(x,y, test_size=0.2)

from sklearn.svm import SVC
classifier = SVC(kernel='linear')
classifier.fit(x_train, y_train)
predictions=classifier.predict(x_test)

from sklearn.metrics import confusion_matrix,accuracy_score
print(confusion_matrix(y_test, predictions))

print(accuracy_score(y_test, predictions))

              Deep Learning

import numpy as np
import keras
from keras.models import Sequential
from keras.layers import Dense

input2=np.array([1,2,3,4,5,6])
Output2=np.array([4,5,6,7,8,9])
print(input2, Output2)

model=Sequential()
model.add(Dense(units=1, input_shape=[1]))
model.compile(optimize='sgd', loss='mean_squared_error')
model.summary()

import matplotlib.pyplot as plt
from wordcloud import WordCloud
test="""Hi prajwal i am going Abeyaantrix"""
WC=WordCloud().generate(test)
plt.imshow(WC)
plt.axis('off')
plt.show()



text="""Hi prajwal i am going Abeyaantrix"""
import string
print(' list of punctuations=\n\n',string.punctuation)
S=string.punctuation

Text="""hi mallesh where is abeyaantrix?,malleshreplied as,abeyaantrix softlab is in Davangere,
davangere is in karnataka!"""
import nltk
from nltk.corpus import stopwords
stop_words=nltk.corpus.stopwords.words('english')
print(stop_words)

Text_stop="".join(item for item in Text.split()if item not in stop_words)
print(Text)
print()
print('-----------after removing stopwords--------------')
print()
print(Text_stop)

Text="""you look smart,he looks like star,you are looking awesome"""
import nltk
from nltk.tokenize import word_tokenize
from nltk.stem import *
tokens=word_tokenize(Text)
print(tokens)

stemmer=nltk.stem.PorterStemmer()
T_stem=" ".join([stemmer.stem(item)for  item in tokens])
T_stem

Text="""you look smart,he looks like star,you are looking awesome"""
import nltk
from nltk.tokenize import word_tokenize
nltk.download('wordnet')
nltk.download('owm-1.4')
nltk.download('punkt')
tokens=word_tokenize(Text)
print(tokens)

from nltk.stem.wordnet import WordNetLemmatizer
Lemma=nltk.stem.WordNetLemmatizer()
T_stem=" ".join([Lemma.lemmatize(item)for  item in tokens])
T_stem




